{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b030cc",
   "metadata": {},
   "source": [
    "# 0 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56592644",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load default packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import lightgbm as lgb\n",
    "import statistics \n",
    "\n",
    "# set random\n",
    "seed = 1234\n",
    "random.seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# no warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "\n",
    "# 64 bit\n",
    "import sys\n",
    "def is_64bit() -> bool:\n",
    "    return sys.maxsize > 2**32\n",
    "is_64bit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load embedding-SBERT packages\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "### Load t-SNE packages\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "### Load xgboost packages\n",
    "import xgboost\n",
    "\n",
    "### Load prediction packages\n",
    "from sklearn import metrics, preprocessing, linear_model, svm, gaussian_process, neighbors\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,r2_score,accuracy_score,balanced_accuracy_score,roc_curve,auc,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# classification\n",
    "from sklearn.multiclass import OneVsRestClassifier ##### !!!! MultiClass Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from xgboost.sklearn import XGBClassifier #XGBoost Classifier\n",
    "from sklearn.svm import SVC #Support Vector Machine\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN (k-nearest neighbor)\n",
    "from sklearn.linear_model import LogisticRegression #Logistic Regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Gradient Boosting Classifier\n",
    "from lightgbm import LGBMClassifier #LGBM Classifier\n",
    "from sklearn.naive_bayes import GaussianNB #Naive Bayes (Gaussian)\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes (Multinomial)\n",
    "from sklearn.linear_model import SGDClassifier #Stochastic Gradient Descent Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# regression\n",
    "from sklearn.linear_model import LinearRegression #LinearR\n",
    "from sklearn.svm import SVR #Support Vector Machine\n",
    "from xgboost.sklearn import XGBRegressor #XGBoost\n",
    "from sklearn.ensemble import RandomForestRegressor #Random Forest\n",
    "from lightgbm import LGBMRegressor #LGBM Regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor #KNN (k-nearest neighbor)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import BayesianRidge \n",
    "from sklearn.linear_model import SGDRegressor #Stochastic Gradient Descent Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea54003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713dba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45809bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076794c9",
   "metadata": {},
   "source": [
    "# 1 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import FLIP raw data\n",
    "dfFLIP = pd.read_csv('/Users/path/FLIP_20220814.csv',header=0)\n",
    "df2010 = dfFLIP.loc[dfFLIP[\"FLIP_year\"]==2010].reset_index(drop=True)\n",
    "df2013 = dfFLIP.loc[dfFLIP[\"FLIP_year\"]==2013].reset_index(drop=True)\n",
    "df2017 = dfFLIP.loc[dfFLIP[\"FLIP_year\"]==2017].reset_index(drop=True)\n",
    "df2020 = dfFLIP.loc[dfFLIP[\"FLIP_year\"]==2020].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38506c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding Algorithm (too slow therefore input embedding results from other computer)\n",
    "# (0_SBERT_processing_FLIP_20220815)\n",
    "# data = data2017\n",
    "# i = data['i'].to_list()\n",
    "# ns = data['Product_n'].to_list()\n",
    "# emb = model.encode(i,show_progress_bar=True)\n",
    "# emb = model.encode(ns,show_progress_bar=True)\n",
    "\n",
    "### Import Emdedding raw data\n",
    "emb2017n = np.load('/Users/path/emb_name_FLIP_2017_20220815.npz')['emb']\n",
    "emb2017i = np.load('/Users/path/emb_ingred_FLIP_2017_20220815.npz')['emb']\n",
    "emb2017b = np.load('/Users/path/emb_brand_FLIP_2017_20220815.npz')['emb']\n",
    "\n",
    "emb2020n = np.load('/Users/path/emb_name_FLIP_2020_20220815.npz')['emb']\n",
    "emb2020i = np.load('/Users/path/emb_ingred_FLIP_2020_20220815.npz')['emb']\n",
    "emb2020b = np.load('/Users/path/emb_brand_FLIP_2020_20220815.npz')['emb']\n",
    "\n",
    "### Creating Embedding combined data for n+ingred+b, n+b, n+ingred\n",
    "# can custumize into emb2017ni and emb2017nbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228998b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4af5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1e09c3",
   "metadata": {},
   "source": [
    "# 2 Visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248e5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df2017\n",
    "emb = emb2017ni\n",
    "dfset = \"df2017-name/ingredient\"\n",
    "print(dfset)\n",
    "\n",
    "df_a = df.loc[((df[\"TRA_Cat\"] != \"ZY\")& (df[\"TRA_Cat\"] != \"ZX\")),]\n",
    "df_b = df_a.loc[df_a[\"Product_Name\"].notna(),].copy()\n",
    "df_c = df_b.loc[df_b[\"Ingredients\"].notna(),].copy()\n",
    "df_d = df_c.loc[df_c[\"Brand\"].notna(),].copy()\n",
    "#df_c = df_c.drop_duplicates(subset='FLIP_UPC',keep='first') ######## unique UPC\n",
    "df_e = df_d.loc[df_d['TRA_Cat'].notna(),].copy()\n",
    "df_o = df_e.loc[df_e['TRA_Cat_code'].notna(),].copy()\n",
    "print(\"FLIP_raw\",df.shape,\"after remove ZY ZX\", df_a.shape, \"after Product_Name NA\", df_b.shape, \"after Ingredients NA\", df_c.shape, \n",
    "      \"after Brand NA\", df_d.shape, \"after TRA validation NA\", df_e.shape, \"after TRA_code validation NA\", df_o.shape)\n",
    "\n",
    "locations = df_o.index.to_list()\n",
    "emb_o = emb[locations]\n",
    "\n",
    "tsne = TSNE(random_state=1234, n_jobs=8)\n",
    "x_embedded = tsne.fit_transform(emb_o)\n",
    "\n",
    "palette = sns.set_palette(sns.color_palette(colors,len(set(df_o['TRA_Cat'].to_list()))))\n",
    "plt.figure(figsize=(10,10), dpi=120)\n",
    "sns.scatterplot(x_embedded[:,0], x_embedded[:,1], hue=df_o['TRA_Cat'].to_list(), legend='full', palette=palette)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3c493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df2020\n",
    "emb = emb2020ni\n",
    "dfset = \"df2020-name/ingredient\"\n",
    "print(dfset)\n",
    "\n",
    "df_a = df.loc[((df[\"TRA_Cat\"] != \"ZY\")& (df[\"TRA_Cat\"] != \"ZX\")),]\n",
    "df_b = df_a.loc[df_a[\"Product_Name\"].notna(),].copy()\n",
    "df_c = df_b.loc[df_b[\"Ingredients\"].notna(),].copy()\n",
    "df_d = df_c.loc[df_c[\"Brand\"].notna(),].copy()\n",
    "#df_c = df_c.drop_duplicates(subset='FLIP_UPC',keep='first') ######## unique UPC\n",
    "df_e = df_d.loc[df_d['TRA_Cat'].notna(),].copy()\n",
    "df_o = df_e.loc[df_e['TRA_Cat_code'].notna(),].copy()\n",
    "print(\"FLIP_raw\",df.shape,\"after remove ZY ZX\", df_a.shape, \"after Product_Name NA\", df_b.shape, \"after Ingredients NA\", df_c.shape, \n",
    "      \"after Brand NA\", df_d.shape, \"after TRA validation NA\", df_e.shape, \"after TRA_code validation NA\", df_o.shape)\n",
    "\n",
    "locations = df_o.index.to_list()\n",
    "emb_o = emb[locations]\n",
    "\n",
    "tsne = TSNE(random_state=1234, n_jobs=8)\n",
    "x_embedded = tsne.fit_transform(emb_o)\n",
    "\n",
    "palette = sns.set_palette(sns.color_palette(colors,len(set(df_o['TRA_Cat'].to_list()))))\n",
    "plt.figure(figsize=(10,10), dpi=120)\n",
    "sns.scatterplot(x_embedded[:,0], x_embedded[:,1], hue=df_o['TRA_Cat'].to_list(), legend='full', palette=palette)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b71c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639f99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6524db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cbdf3c",
   "metadata": {},
   "source": [
    "# 3 TRA_Cat Algrothim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2020\n",
    "emb = emb2020ni\n",
    "dfset = \"df2020-TRA_Cat-name/ingredient\"\n",
    "print(dfset) \n",
    "\n",
    "df_a = df.loc[((df[\"TRA_Cat\"] != \"ZY\")& (df[\"TRA_Cat\"] != \"ZX\")),]\n",
    "df_b = df_a.loc[df_a[\"Product_Name\"].notna(),].copy()\n",
    "df_c = df_b.loc[df_b[\"Ingredients\"].notna(),].copy()\n",
    "df_d = df_c.loc[df_c[\"Brand\"].notna(),].copy()\n",
    "#df_c = df_c.drop_duplicates(subset='FLIP_UPC',keep='first') ######## unique UPC\n",
    "df_e = df_d.loc[df_d['TRA_Cat'].notna(),].copy()\n",
    "df_o = df_e.loc[df_e['TRA_Cat_code'].notna(),].copy()\n",
    "print(\"FLIP_raw\",df.shape,\"after remove ZY ZX\", df_a.shape, \"after Product_Name NA\", df_b.shape, \"after Ingredients NA\", df_c.shape, \n",
    "      \"after Brand NA\", df_d.shape, \"after TRA validation NA\", df_e.shape, \"after TRA_code validation NA\", df_o.shape)\n",
    "\n",
    "locations = df_o.index.to_list()\n",
    "emb_o = emb[locations]\n",
    "\n",
    "x = emb_o\n",
    "y = df_o['TRA_Cat_code']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=random.seed)\n",
    "\n",
    "clf1ni = SGDClassifier(penalty='elasticnet',n_jobs=8, random_state=1234)\n",
    "clf1ni.fit(x_train, y_train)\n",
    "y_pred = clf1ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print('Elastic Net Acc: {:.2f}'.format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print('Elastic Net Balanced Accuracy Score: {:.2f}'.format(balanced_accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['ElasticNet'] = measures\n",
    "\n",
    "clf2ni = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2ni.fit(x_train, y_train)\n",
    "y_pred = clf2ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print(\"KNN Acc: {:.2f}\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(\"KNN Balanced Accuracy Score: %.2g\" % balanced_accuracy_score(y_true, y_pred))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['KNN'] = measures\n",
    "\n",
    "clf3ni = OneVsRestClassifier(xgboost.XGBClassifier(n_estimators=100,learning_rate=0.3,max_depth=6, subsample=1, gamma=0,reg_lambda=1,max_delta_step=0, colsample_bytree=1,min_child_weight=1, n_jobs=10,random_state=random.seed, reg_alpha=0,num_class=0,nthread=4,eval_metric='auc'))\n",
    "clf3ni.fit(x_train, y_train)\n",
    "y_pred = clf3ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print(\"XGBoost Acc: {:.2f}\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(\"XGBoost Balanced Accuracy Score: %.2g\" % balanced_accuracy_score(y_true, y_pred))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['XGBoost'] = measures\n",
    "\n",
    "results_table1ni = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "display(results_table1ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf3ni\n",
    "### by each TRA_Cat categories\n",
    "### by each TRA_Cat categories \n",
    "### by each TRA_Cat categories \n",
    "from sklearn.utils.multiclass import unique_labels ##### edited labels\n",
    "TRA_Cat_list = unique_labels(y) ##### edited labels\n",
    "TRA_Cat_list = [str(int(x)) for x in TRA_Cat_list] \n",
    "clf3ni_traw = metrics.classification_report(y_true, y_pred) #print(t3raw)\n",
    "clf3ni_t = classification_report(y_true, y_pred, output_dict = True, digits=2)\n",
    "clf3ni_t = pd.DataFrame(clf3ni_t)\n",
    "\n",
    "### confusion matrix (non-normalized + normalized) clf3ni\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "sns.set(rc={'figure.figsize':(10,10)}, style='ticks', font=\"Arial\", font_scale=0.75)\n",
    "\n",
    "class_names = df2020.TRA_Cat_code\n",
    "display_labels = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X']\n",
    "#display_labels =[ '1.',  '3.',  '8'., '13'., '18'.,  '2'., 15., 19., 21.,  4., 10.,  5., 11., 22., 14., 20.,  9., 12., 23.,  6., 16.,  7.,  0., 17.]\n",
    "values_format=['.0f','.2f']\n",
    "cmap=[plt.cm.Blues, plt.cm.Blues]\n",
    "\n",
    "titles_options = [(\"Confusion Matrix \\n\", None), #(\"Confusion Matrix \\n (test sample)\", None),\n",
    "                  (\"Confusion Matrix \\n\", \"pred\"),] # normolizer: 'true' 'pred' 'all' None\n",
    "\n",
    "for i in range(len(titles_options)):\n",
    "    title, normalize = titles_options[i]\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(clf3ni, ###### change here\n",
    "            x_test, y_test, display_labels=display_labels,\n",
    "            cmap=cmap[i], normalize=normalize, values_format=values_format[i],)  # include_values=False, # xticks_rotation=270,\n",
    "    disp.ax_.set_title(title, fontsize=13,fontweight=\"bold\") # ,\n",
    "    disp.ax_.set_xlabel('Predicted TRA Category', fontsize=13)\n",
    "    #plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    disp.ax_.set_ylabel('True TRA Category', fontsize=13)\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c3380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8aa00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1b8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26fab3b",
   "metadata": {},
   "source": [
    "# 4 TRA_Item Algrothm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794a55b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df2020\n",
    "emb = emb2020ni\n",
    "dfset = \"df2020-TRA_Item-name/ingredient\"\n",
    "print(dfset) \n",
    "\n",
    "df_a = df.loc[((df[\"TRA_Item\"] != \"ZY\")& (df[\"TRA_Item\"] != \"ZX\")),]\n",
    "df_b = df_a.loc[df_a[\"Product_Name\"].notna(),].copy()\n",
    "df_c = df_b.loc[df_b[\"Ingredients\"].notna(),].copy()\n",
    "df_d = df_c.loc[df_c[\"Brand\"].notna(),].copy()\n",
    "#df_c = df_c.drop_duplicates(subset='FLIP_UPC',keep='first') ######## unique UPC\n",
    "df_e = df_d.loc[df_d['TRA_Item'].notna(),].copy()\n",
    "df_o = df_e.loc[df_e['TRA_Item_code'].notna(),].copy()\n",
    "print(\"FLIP_raw\",df.shape,\"after remove ZY ZX\", df_a.shape, \"after Product_Name NA\", df_b.shape, \"after Ingredients NA\", df_c.shape, \n",
    "      \"after Brand NA\", df_d.shape, \"after TRA validation NA\", df_e.shape, \"after TRA_code validation NA\", df_o.shape)\n",
    "\n",
    "locations = df_o.index.to_list()\n",
    "emb_o = emb[locations]\n",
    "\n",
    "x = emb_o\n",
    "y = df_o['TRA_Item_code']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=random.seed)\n",
    "\n",
    "clfbb1ni = SGDClassifier(penalty='elasticnet',n_jobs=8, random_state=1234)\n",
    "clfbb1ni.fit(x_train, y_train)\n",
    "y_pred = clfbb1ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print('Elastic Net Acc: {:.2f}'.format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print('Elastic Net Balanced Accuracy Score: {:.2f}'.format(balanced_accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['ElasticNet'] = measures\n",
    "\n",
    "clfb2ni = KNeighborsClassifier(n_neighbors=3)\n",
    "clfb2ni.fit(x_train, y_train)\n",
    "y_pred = clfb2ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print(\"KNN Acc: {:.2f}\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(\"KNN Balanced Accuracy Score: %.2g\" % balanced_accuracy_score(y_true, y_pred))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['KNN'] = measures\n",
    "\n",
    "clfb3ni = OneVsRestClassifier(xgboost.XGBClassifier(n_estimators=100,learning_rate=0.3,max_depth=6, subsample=1, gamma=0,reg_lambda=1,max_delta_step=0, colsample_bytree=1,min_child_weight=1, n_jobs=10,random_state=random.seed, reg_alpha=0,num_class=0,nthread=4,eval_metric='auc'))\n",
    "clfb3ni.fit(x_train, y_train)\n",
    "y_pred = clfb3ni.predict(x_test)\n",
    "y_true = y_test\n",
    "print(\"XGBoost Acc: {:.2f}\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(\"XGBoost Balanced Accuracy Score: %.2g\" % balanced_accuracy_score(y_true, y_pred))\n",
    "measures = dict()\n",
    "measures['Accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "measures['Balanced-Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "measures['n_train'] = x_train.shape[0]\n",
    "measures['n'] = df_o.shape[0]\n",
    "measures['dfset'] = dfset\n",
    "results['XGBoost'] = measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756287c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ecd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508745c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parser-env",
   "language": "python",
   "name": "parser-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
